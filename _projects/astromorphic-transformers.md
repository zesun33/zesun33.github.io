---
layout: page
title: Astromorphic Transformers
description: Bio-inspired neural architectures incorporating astrocyte-neuron interactions for efficient sequence processing
importance: 1
category: work
related_publications: true
---

## Astromorphic Transformers: Astrocyte-Enhanced Neural Architecture

This research project develops **astromorphic transformers**, a novel neural network architecture that incorporates the critical role of **astrocytes** - brain cells that constitute more than 50% of human brain cells - in neuromorphic computing. The work bridges the gap between biological neural networks and artificial intelligence hardware.

### Research Overview

Lead Student Researcher, 2023â€“Present. Developed a **neuromorphic algorithmic framework** for transformer models with **astrocytic memory**, enabling biologically inspired sequence learning that mimics actual brain functionality.

### Key Research Contributions

ðŸ§  **Bioplausible Modeling**: Integration of Hebbian and presynaptic plasticities in neuron-astrocyte networks

âš¡ **Enhanced Performance**: Improved accuracy and learning speed in sentiment analysis and image classification tasks

ðŸ”¬ **Novel Architecture**: First comprehensive incorporation of astrocytic characteristics in transformer self-attention mechanisms

ðŸ“Š **Superior Results**: Better perplexity on WikiText-2 dataset compared to conventional models

### Technical Innovations

The project leverages astrocytic **non-linearities** and **memory retention** to improve long-range dependency processing:

1. **Neuron-Synapse-Astrocyte Interactions**: Bioplausible modeling of cellular interactions
2. **Self-Attention Enhancement**: Mapping neuron-astrocyte computations to attention mechanisms
3. **Temporal Memory**: Astrocytic memory for improved context retention
4. **Energy Efficiency**: Bio-inspired optimization for reduced computational complexity

### Experimental Validation

**Datasets Tested**:

- **IMDB** (sentiment classification)
- **CIFAR-10** (image classification)
- **WikiText-2** (natural language generation)

**Performance Gains**:

- Improved accuracy across all tested datasets
- Enhanced learning speed and convergence
- Better generalization and stability

### Publications

- **IEEE Transactions on Cognitive and Developmental Systems** (2025) - "Delving Deeper Into Astromorphic Transformers"
- **OpenReview** (2024) - "RMAAT: A Bio-Inspired Approach for Efficient Long-Context Sequence Processing in Transformers"

### Research Team

**Principal Investigator**: Md Zesun Ahmed Mia  
**Collaborators**: Malyaban Bal, Abhronil Sengupta  
**Institution**: Pennsylvania State University  
**Funding**: Lead Student Researcher role, 2023â€“Present

### Impact and Future Directions

This work advances the field of **neuromorphic computing** by demonstrating how astrocytic characteristics can enhance computational models, paving the way for more efficient and biologically realistic AI systems.
